{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from pyvista import examples\n",
    "import tifffile as tiff\n",
    "\n",
    "# Load disparity map and corresponding RGB image\n",
    "disparity_map = tiff.imread('../data/kramlich-subset/depth/device_741df78f3cf22b9e_camera1_1722960518099.tiff')\n",
    "rgb_image = cv2.imread('../data/kramlich-subset/rgb/device_741df78f3cf22b9e_camera1_1722960518099.jpg')\n",
    "\n",
    "# Handle potential nan or inf values in the disparity map\n",
    "disparity_map[disparity_map < 0] = 0.0\n",
    "\n",
    "# Apply a threshold to avoid near-zero disparities\n",
    "disparity_threshold = 2.0  # Set an appropriate threshold (adjust based on your system)\n",
    "disparity_map[disparity_map < disparity_threshold] = 0.0\n",
    "\n",
    "# Camera parameters (adjust as per your setup)\n",
    "focal_length = 100.0  # Example focal length in pixels\n",
    "baseline = 1.0  # Baseline in meters\n",
    "cx, cy = rgb_image.shape[1] // 2, rgb_image.shape[0] // 2  # Assume image center is the principal point\n",
    "fx, fy = focal_length, focal_length\n",
    "\n",
    "# Construct the Q matrix\n",
    "Q = np.array([[1, 0, 0, -cx],\n",
    "              [0, 1, 0, -cy],\n",
    "              [0, 0, 0, focal_length],\n",
    "              [0, 0, -1.0 / baseline, 0]], dtype=np.float32)\n",
    "\n",
    "# Reproject points into 3D space using the Q matrix\n",
    "points_3d = cv2.reprojectImageTo3D(disparity_map, Q)\n",
    "\n",
    "# Mask out invalid points where disparity was zero or still invalid\n",
    "mask = (disparity_map >= disparity_threshold) & (disparity_map < np.inf)\n",
    "\n",
    "# Extract valid 3D points and corresponding RGB colors\n",
    "valid_points = points_3d[mask]\n",
    "valid_colors = rgb_image[mask].astype(np.float32) / 255.0  # Normalize colors to [0, 1]\n",
    "\n",
    "# Create a PyVista point cloud object\n",
    "point_cloud = pv.PolyData(valid_points)\n",
    "\n",
    "# Add RGB colors to the point cloud\n",
    "point_cloud['RGB'] = valid_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming valid_points contains your (X, Y, Z) data and valid_colors contains (R, G, B)\n",
    "valid_points = np.array(valid_points)\n",
    "\n",
    "# Option 1: Center the points around the mean (without scaling)\n",
    "centered_points = valid_points - np.mean(valid_points, axis=0)\n",
    "\n",
    "# Option 2: If you want to scale (optional), apply a fixed scaling factor\n",
    "# This is not necessary but can help if the points are too far apart or too close.\n",
    "scaling_factor = 1  # You can set this to another value to adjust the point cloud's scale\n",
    "scaled_points = centered_points * scaling_factor\n",
    "\n",
    "# Convert the RGB colors to the range [0, 255] for saving in PLY format\n",
    "valid_colors_255 = (valid_colors * 255).astype(np.uint8)  # Convert colors back to 255 scale\n",
    "\n",
    "# Combine the points and colors into one array for saving\n",
    "points_with_colors = np.hstack([scaled_points, valid_colors_255])\n",
    "\n",
    "# Prepare the PLY file header\n",
    "ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex {0}\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "'''.format(len(points_with_colors))\n",
    "\n",
    "# Write the point cloud to a PLY file\n",
    "with open('point_cloud.ply', 'w') as f:\n",
    "    f.write(ply_header)\n",
    "    np.savetxt(f, points_with_colors, fmt='%f %f %f %d %d %d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def find_closest_points(source_points, target_points):\n",
    "    \"\"\"Find the closest points in target for each point in source.\"\"\"\n",
    "    closest_points = np.zeros_like(source_points)\n",
    "    distances = np.zeros(source_points.shape[0])\n",
    "\n",
    "    for i in range(source_points.shape[0]):\n",
    "        diff = target_points - source_points[i]\n",
    "        dist_sq = np.sum(diff ** 2, axis=1)\n",
    "        closest_idx = np.argmin(dist_sq)\n",
    "        closest_points[i] = target_points[closest_idx]\n",
    "        distances[i] = np.sqrt(dist_sq[closest_idx])\n",
    "\n",
    "    return closest_points, distances\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_mean(points):\n",
    "    \"\"\"Manually calculate the mean of a set of points (Numba-compatible).\"\"\"\n",
    "    return np.sum(points, axis=0) / points.shape[0]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def best_fit_transform(A, B):\n",
    "    \"\"\"Calculates the best-fit transform that maps points A to points B.\"\"\"\n",
    "    assert A.shape == B.shape\n",
    "\n",
    "    # Manually compute centroids\n",
    "    centroid_A = calculate_mean(A)\n",
    "    centroid_B = calculate_mean(B)\n",
    "\n",
    "    # Center the points\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    H = np.dot(AA.T, BB)\n",
    "\n",
    "    # Compute the Singular Value Decomposition (SVD)\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "\n",
    "    # Compute rotation\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # Ensure a proper rotation matrix (det(R) should be 1)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # Compute translation\n",
    "    t = centroid_B.T - np.dot(R, centroid_A.T)\n",
    "\n",
    "    return R, t\n",
    "\n",
    "@jit(nopython=True)\n",
    "def icp(source_points, target_points, max_iterations=100, tolerance=1e-6):\n",
    "    \"\"\"Perform ICP to align source_points with target_points.\"\"\"\n",
    "    prev_error = float('inf')\n",
    "\n",
    "    # Initial alignment (assume identity matrix)\n",
    "    source_transformed = np.copy(source_points)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # Find closest points in target for each point in source\n",
    "        closest_points, distances = find_closest_points(source_transformed, target_points)\n",
    "\n",
    "        # Compute the best-fit transform\n",
    "        R, t = best_fit_transform(source_transformed, closest_points)\n",
    "\n",
    "        # Apply the transformation\n",
    "        source_transformed = np.dot(source_transformed, R.T) + t\n",
    "\n",
    "        # Check for convergence\n",
    "        mean_error = np.sum(distances) / distances.shape[0]\n",
    "        if abs(prev_error - mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "\n",
    "    return source_transformed, R, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from pyvista import examples\n",
    "import tifffile as tiff\n",
    "\n",
    "\n",
    "# Load disparity map and corresponding RGB image\n",
    "disparity_map_1 = tiff.imread('../data/kramlich-subset/depth/device_741df78f3cf22b9e_camera1_1722960518099.tiff')\n",
    "rgb_image_1 = cv2.imread('../data/kramlich-subset/rgb/device_741df78f3cf22b9e_camera1_1722960518099.jpg')\n",
    "disparity_map_2 = tiff.imread('../data/kramlich-subset/depth/device_741df78f3cf22b9e_camera1_1722960517996.tiff')\n",
    "rgb_image_2 = cv2.imread('../data/kramlich-subset/rgb/device_741df78f3cf22b9e_camera1_1722960517996.jpg')\n",
    "\n",
    "# Convert the images from BGR to RGB\n",
    "rgb_image_1 = cv2.cvtColor(rgb_image_1, cv2.COLOR_BGR2RGB)\n",
    "rgb_image_2 = cv2.cvtColor(rgb_image_2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Set parameters for your stereo setup (adjust based on your camera)\n",
    "focal_length = 100.0  # Focal length in pixels\n",
    "baseline = 1.0  # Baseline in meters\n",
    "\n",
    "# Process both disparity maps and images into 3D point clouds\n",
    "def disparity_to_point_cloud(disparity_map, rgb_image, threshold=2.0):\n",
    "    \"\"\"Convert a disparity map and corresponding RGB image into a point cloud.\"\"\"\n",
    "    # Handle any negative or invalid values in the disparity map\n",
    "    disparity_map[disparity_map < 0] = 0.0\n",
    "    disparity_map[disparity_map < threshold] = 0.0\n",
    "\n",
    "    # Image and camera parameters (adjust as necessary)\n",
    "    cx, cy = rgb_image.shape[1] // 2, rgb_image.shape[0] // 2  # Assume the image center is the principal point\n",
    "    fx, fy = focal_length, focal_length\n",
    "\n",
    "    # Construct the Q matrix for reprojection to 3D\n",
    "    Q = np.array([[1, 0, 0, -cx],\n",
    "                  [0, 1, 0, -cy],\n",
    "                  [0, 0, 0, focal_length],\n",
    "                  [0, 0, -1.0 / baseline, 0]], dtype=np.float32)\n",
    "\n",
    "    # Reproject to 3D\n",
    "    points_3d = cv2.reprojectImageTo3D(disparity_map, Q)\n",
    "\n",
    "    # Mask invalid points (where disparity is zero or invalid)\n",
    "    mask = (disparity_map >= threshold) & (disparity_map < np.inf)\n",
    "\n",
    "    # Extract valid points and their corresponding colors\n",
    "    valid_points = points_3d[mask]\n",
    "    valid_colors = rgb_image[mask].astype(np.float32) / 255.0  # Normalize colors to [0, 1]\n",
    "\n",
    "    return valid_points, valid_colors\n",
    "\n",
    "# Get point clouds for both maps\n",
    "valid_points_1, valid_colors_1 = disparity_to_point_cloud(disparity_map_1, rgb_image_1)\n",
    "valid_points_2, valid_colors_2 = disparity_to_point_cloud(disparity_map_2, rgb_image_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ICP to align point clouds\n",
    "aligned_points_2, R, t = icp(valid_points_2, valid_points_1)\n",
    "\n",
    "# Merge the aligned points with the first point cloud\n",
    "merged_points = np.vstack((valid_points_1, aligned_points_2))\n",
    "merged_colors = np.vstack((valid_colors_1, valid_colors_2))\n",
    "\n",
    "# Create a PyVista point cloud object for the merged point cloud\n",
    "merged_point_cloud = pv.PolyData(merged_points)\n",
    "merged_point_cloud['RGB'] = merged_colors\n",
    "\n",
    "# Visualize the combined point cloud\n",
    "plotter = pv.Plotter()\n",
    "plotter.add_points(merged_point_cloud, scalars='RGB', rgb=True, point_size=5)\n",
    "plotter.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
